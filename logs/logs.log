2022-10-02 12:47:36.519  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Starting WorkerApplication v0.0.1-SNAPSHOT using Java 11.0.14.1 on e11802e7f438 with PID 1 (/opt/worker-0.0.1-SNAPSHOT.jar started by root in /)
2022-10-02 12:47:36.526  INFO  1 --- [main] com.worker.worker.WorkerApplication      : The following 1 profile is active: "docker"
2022-10-02 12:47:37.625  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Started WorkerApplication in 1.654 seconds (JVM running for 2.073)
2022-10-02 12:47:37.647  INFO  1 --- [scheduled-task-pool-1] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [logs-kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = logs-module
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = logs-module-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

2022-10-02 12:47:37.745  WARN  1 --- [scheduled-task-pool-1] org.apache.kafka.clients.ClientUtils     : Couldn't resolve server logs-kafka:9092 from bootstrap.servers as DNS resolution failed for logs-kafka
2022-10-02 12:47:37.747  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2022-10-02 12:47:37.747  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-02 12:47:37.747  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2022-10-02 12:47:37.748  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for logs-module unregistered
2022-10-02 12:47:37.751 ERROR  1 --- [scheduled-task-pool-1] o.s.s.s.TaskUtils$LoggingErrorHandler    : Unexpected error occurred in scheduled task

org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:823) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:664) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:645) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:625) ~[kafka-clients-3.1.1.jar!/:na]
	at com.worker.worker.kafka.consumer.KafkaMultiplyThreadConsumer.<init>(KafkaMultiplyThreadConsumer.java:27) ~[classes!/:0.0.1-SNAPSHOT]
	at com.worker.worker.kafka.runner.ConsumerRunner.run(ConsumerRunner.java:26) ~[classes!/:0.0.1-SNAPSHOT]
	at com.worker.worker.config.ApplicationConfig.runConsumer(ApplicationConfig.java:17) ~[classes!/:0.0.1-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84) ~[spring-context-5.3.22.jar!/:5.3.22]
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) ~[spring-context-5.3.22.jar!/:5.3.22]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na]
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:730) ~[kafka-clients-3.1.1.jar!/:na]
	... 18 common frames omitted

2022-10-02 12:50:45.072  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Starting WorkerApplication v0.0.1-SNAPSHOT using Java 11.0.14.1 on f8f6a5df396e with PID 1 (/opt/worker-0.0.1-SNAPSHOT.jar started by root in /)
2022-10-02 12:50:45.074  INFO  1 --- [main] com.worker.worker.WorkerApplication      : The following 1 profile is active: "docker"
2022-10-02 12:50:45.988  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Started WorkerApplication in 1.331 seconds (JVM running for 1.673)
2022-10-02 12:50:46.011  INFO  1 --- [scheduled-task-pool-1] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [logs-kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = logs-module
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = logs-module-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

2022-10-02 12:50:46.102  WARN  1 --- [scheduled-task-pool-1] org.apache.kafka.clients.ClientUtils     : Couldn't resolve server logs-kafka:9092 from bootstrap.servers as DNS resolution failed for logs-kafka
2022-10-02 12:50:46.105  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.common.metrics.Metrics  : Metrics scheduler closed
2022-10-02 12:50:46.105  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.common.metrics.Metrics  : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-02 12:50:46.105  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.common.metrics.Metrics  : Metrics reporters closed
2022-10-02 12:50:46.107  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.consumer for logs-module unregistered
2022-10-02 12:50:46.112 ERROR  1 --- [scheduled-task-pool-1] o.s.s.s.TaskUtils$LoggingErrorHandler    : Unexpected error occurred in scheduled task

org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:823) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:664) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:645) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:625) ~[kafka-clients-3.1.1.jar!/:na]
	at com.worker.worker.kafka.consumer.KafkaMultiplyThreadConsumer.<init>(KafkaMultiplyThreadConsumer.java:27) ~[classes!/:0.0.1-SNAPSHOT]
	at com.worker.worker.kafka.runner.ConsumerRunner.run(ConsumerRunner.java:26) ~[classes!/:0.0.1-SNAPSHOT]
	at com.worker.worker.config.ApplicationConfig.runConsumer(ApplicationConfig.java:17) ~[classes!/:0.0.1-SNAPSHOT]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:na]
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[na:na]
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84) ~[spring-context-5.3.22.jar!/:5.3.22]
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) ~[spring-context-5.3.22.jar!/:5.3.22]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[na:na]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na]
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48) ~[kafka-clients-3.1.1.jar!/:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:730) ~[kafka-clients-3.1.1.jar!/:na]
	... 18 common frames omitted

2022-10-02 13:04:47.808  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Starting WorkerApplication v0.0.1-SNAPSHOT using Java 11.0.14.1 on cf62897d33c1 with PID 1 (/opt/worker-0.0.1-SNAPSHOT.jar started by root in /)
2022-10-02 13:04:47.810  INFO  1 --- [main] com.worker.worker.WorkerApplication      : The following 1 profile is active: "docker"
2022-10-02 13:04:48.789  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Started WorkerApplication in 1.475 seconds (JVM running for 1.922)
2022-10-02 13:04:48.817  INFO  1 --- [scheduled-task-pool-1] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [logs-kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = logs-module
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = logs-module-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

2022-10-02 13:04:48.967  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.1.1
2022-10-02 13:04:48.968  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 97671528ba54a138
2022-10-02 13:04:48.968  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1664715888965
2022-10-02 13:04:48.970  INFO  1 --- [scheduled-task-pool-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=logs-module, groupId=logs-module-group] Subscribed to topic(s): task-queue
2022-10-02 13:04:49.287  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=logs-module, groupId=logs-module-group] Resetting the last seen epoch of partition task-queue-0 to 1 since the associated topicId changed from null to a2uZ2fs4TuuD9M8g-sdtJg
2022-10-02 13:04:49.292  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=logs-module, groupId=logs-module-group] Cluster ID: XNtoi0QORy-2jty-3PuJoQ
2022-10-02 13:04:49.917  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Discovered group coordinator logs-kafka:9092 (id: 2147482645 rack: null)
2022-10-02 13:04:49.922  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] (Re-)joining group
2022-10-02 13:04:49.947  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Request joining group due to: need to re-join with the given member-id
2022-10-02 13:04:49.947  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] (Re-)joining group
2022-10-02 13:04:49.966  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Successfully joined group with generation Generation{generationId=1, memberId='logs-module-38d163d1-1f28-4540-ad3d-e113f1369b7f', protocol='range'}
2022-10-02 13:04:50.017  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Finished assignment for group at generation 1: {logs-module-38d163d1-1f28-4540-ad3d-e113f1369b7f=Assignment(partitions=[task-queue-0])}
2022-10-02 13:04:50.069  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Successfully synced group in generation Generation{generationId=1, memberId='logs-module-38d163d1-1f28-4540-ad3d-e113f1369b7f', protocol='range'}
2022-10-02 13:04:50.069  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Notifying assignor about the new Assignment(partitions=[task-queue-0])
2022-10-02 13:04:50.072  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Adding newly assigned partitions: task-queue-0
2022-10-02 13:04:50.090  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Found no committed offset for partition task-queue-0
2022-10-02 13:06:53.058  INFO  1 --- [main] c.e.e.ElkLogSystemApplication            : Starting ElkLogSystemApplication v0.0.1-SNAPSHOT using Java 11.0.14.1 on bee45e10be55 with PID 1 (/opt/elkLogSystem-0.0.1-SNAPSHOT.jar started by root in /)
2022-10-02 13:06:53.061  INFO  1 --- [main] c.e.e.ElkLogSystemApplication            : The following 1 profile is active: "docker"
2022-10-02 13:06:54.038  INFO  1 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2022-10-02 13:06:54.048  INFO  1 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2022-10-02 13:06:54.049  INFO  1 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.65]
2022-10-02 13:06:54.111  INFO  1 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2022-10-02 13:06:54.111  INFO  1 --- [main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1001 ms
2022-10-02 13:06:54.602  INFO  1 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2022-10-02 13:06:54.613  INFO  1 --- [main] c.e.e.ElkLogSystemApplication            : Started ElkLogSystemApplication in 2.014 seconds (JVM running for 2.411)
2022-10-02 13:13:49.387  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=logs-module, groupId=logs-module-group] Node -1 disconnected.
2022-10-02 13:21:48.631  INFO  1 --- [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-10-02 13:21:48.632  INFO  1 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2022-10-02 13:21:48.634  INFO  1 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 2 ms
2022-10-02 13:21:48.682  INFO CorrelationId=b2e38cdf-c3f8-4bbf-a49b-ec1c00c3aba0 1 --- [http-nio-8080-exec-2] c.e.e.conrollers.MainController          : On index page
2022-10-02 13:21:48.730  INFO CorrelationId=b2e38cdf-c3f8-4bbf-a49b-ec1c00c3aba0 1 --- [http-nio-8080-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [logs-kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = logs-module
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2022-10-02 13:21:48.862  INFO CorrelationId=b2e38cdf-c3f8-4bbf-a49b-ec1c00c3aba0 1 --- [http-nio-8080-exec-2] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=logs-module] Instantiated an idempotent producer.
2022-10-02 13:21:48.913  INFO CorrelationId=b2e38cdf-c3f8-4bbf-a49b-ec1c00c3aba0 1 --- [http-nio-8080-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.1.1
2022-10-02 13:21:48.915  INFO CorrelationId=b2e38cdf-c3f8-4bbf-a49b-ec1c00c3aba0 1 --- [http-nio-8080-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 97671528ba54a138
2022-10-02 13:21:48.915  INFO CorrelationId=b2e38cdf-c3f8-4bbf-a49b-ec1c00c3aba0 1 --- [http-nio-8080-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1664716908911
2022-10-02 13:21:49.228  INFO  1 --- [kafka-producer-network-thread | logs-module] org.apache.kafka.clients.Metadata        : [Producer clientId=logs-module] Resetting the last seen epoch of partition task-queue-0 to 1 since the associated topicId changed from null to a2uZ2fs4TuuD9M8g-sdtJg
2022-10-02 13:21:49.233  INFO  1 --- [kafka-producer-network-thread | logs-module] org.apache.kafka.clients.Metadata        : [Producer clientId=logs-module] Cluster ID: XNtoi0QORy-2jty-3PuJoQ
2022-10-02 13:21:49.236  INFO  1 --- [kafka-producer-network-thread | logs-module] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=logs-module] ProducerId set to 1000 with epoch 0
2022-10-02 13:23:49.311 ERROR  1 --- [kafka-producer-network-thread | logs-module] r.k.sender.internals.DefaultKafkaSender  : error {}

org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for task-queue-0:120000 ms has passed since batch creation

2022-10-02 13:23:49.319 ERROR  1 --- [single-1] reactor.core.publisher.Operators         : Operator called default onErrorDropped

reactor.core.Exceptions$ErrorCallbackNotImplemented: java.lang.NullPointerException
Caused by: java.lang.NullPointerException: null
	at com.elkSystem.elkLogSystem.kafka.KafkaProducer.lambda$sendData$1(KafkaProducer.java:42) ~[classes!/:0.0.1-SNAPSHOT]
	at reactor.core.publisher.LambdaSubscriber.onNext(LambdaSubscriber.java:160) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at reactor.core.publisher.FluxPeek$PeekSubscriber.onNext(FluxPeek.java:200) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onNext(MonoFlatMapMany.java:250) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.runAsync(FluxPublishOn.java:440) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at reactor.core.publisher.FluxPublishOn$PublishOnSubscriber.run(FluxPublishOn.java:527) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:84) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at reactor.core.scheduler.WorkerTask.call(WorkerTask.java:37) ~[reactor-core-3.4.21.jar!/:3.4.21]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[na:na]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na]

2022-10-02 13:30:17.127  WARN  1 --- [SpringApplicationShutdownHook] o.s.b.f.support.DisposableBeanAdapter    : Custom destroy method 'close' on bean with name 'kafkaSender' threw an exception: java.lang.NoSuchMethodError: 'void org.apache.kafka.clients.producer.Producer.close(long, java.util.concurrent.TimeUnit)'
2022-10-02 14:17:35.593  INFO  1 --- [main] c.e.e.ElkLogSystemApplication            : Starting ElkLogSystemApplication v0.0.1-SNAPSHOT using Java 11.0.14.1 on aae374c737f0 with PID 1 (/opt/elkLogSystem-0.0.1-SNAPSHOT.jar started by root in /)
2022-10-02 14:17:35.598  INFO  1 --- [main] c.e.e.ElkLogSystemApplication            : The following 1 profile is active: "docker"
2022-10-02 14:17:36.549  INFO  1 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2022-10-02 14:17:36.559  INFO  1 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2022-10-02 14:17:36.559  INFO  1 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.65]
2022-10-02 14:17:36.621  INFO  1 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2022-10-02 14:17:36.621  INFO  1 --- [main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 976 ms
2022-10-02 14:17:37.129  INFO  1 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2022-10-02 14:17:37.140  INFO  1 --- [main] c.e.e.ElkLogSystemApplication            : Started ElkLogSystemApplication in 2.034 seconds (JVM running for 2.509)
2022-10-02 14:17:58.162  INFO  1 --- [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-10-02 14:17:58.163  INFO  1 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2022-10-02 14:17:58.166  INFO  1 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 2 ms
2022-10-02 14:17:58.221  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [http-nio-8080-exec-1] c.e.e.conrollers.MainController          : On index page
2022-10-02 14:17:58.266  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [http-nio-8080-exec-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [logs-kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = logs-module
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2022-10-02 14:17:58.414  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [http-nio-8080-exec-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=logs-module] Instantiated an idempotent producer.
2022-10-02 14:17:58.468  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [http-nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.1.1
2022-10-02 14:17:58.470  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [http-nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 97671528ba54a138
2022-10-02 14:17:58.470  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [http-nio-8080-exec-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1664720278466
2022-10-02 14:17:58.834  INFO  1 --- [kafka-producer-network-thread | logs-module] org.apache.kafka.clients.Metadata        : [Producer clientId=logs-module] Cluster ID: 4VysX83kR7GqThzjFo45xw
2022-10-02 14:17:58.835  INFO  1 --- [kafka-producer-network-thread | logs-module] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=logs-module] ProducerId set to 0 with epoch 0
2022-10-02 14:17:59.010  INFO  1 --- [single-1] c.e.elkLogSystem.kafka.KafkaProducer     : Message Task sent successfully, topic-partition=task-queue-0 offset=0
2022-10-02 14:18:25.519  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Starting WorkerApplication v0.0.1-SNAPSHOT using Java 11.0.14.1 on 495148e23367 with PID 1 (/opt/worker-0.0.1-SNAPSHOT.jar started by root in /)
2022-10-02 14:18:25.523  INFO  1 --- [main] com.worker.worker.WorkerApplication      : The following 1 profile is active: "docker"
2022-10-02 14:18:26.854  INFO  1 --- [main] com.worker.worker.WorkerApplication      : Started WorkerApplication in 1.733 seconds (JVM running for 2.199)
2022-10-02 14:18:26.937  INFO  1 --- [scheduled-task-pool-1] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [logs-kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = logs-module
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = logs-module-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.BytesDeserializer

2022-10-02 14:18:27.426  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.1.1
2022-10-02 14:18:27.429  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 97671528ba54a138
2022-10-02 14:18:27.429  INFO  1 --- [scheduled-task-pool-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1664720307421
2022-10-02 14:18:27.437  INFO  1 --- [scheduled-task-pool-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=logs-module, groupId=logs-module-group] Subscribed to topic(s): task-queue
2022-10-02 14:18:28.067  INFO  1 --- [scheduled-task-pool-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=logs-module, groupId=logs-module-group] Cluster ID: 4VysX83kR7GqThzjFo45xw
2022-10-02 14:18:28.493  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Discovered group coordinator logs-kafka:9092 (id: 2147482646 rack: null)
2022-10-02 14:18:28.517  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] (Re-)joining group
2022-10-02 14:18:28.581  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Successfully joined group with generation Generation{generationId=1, memberId='logs-module-4a1b4c4a-646d-45e4-9103-a67e733a6210', protocol='range'}
2022-10-02 14:18:28.586  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Finished assignment for group at generation 1: {logs-module-4a1b4c4a-646d-45e4-9103-a67e733a6210=Assignment(partitions=[task-queue-0])}
2022-10-02 14:18:28.610  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Successfully synced group in generation Generation{generationId=1, memberId='logs-module-4a1b4c4a-646d-45e4-9103-a67e733a6210', protocol='range'}
2022-10-02 14:18:28.611  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Notifying assignor about the new Assignment(partitions=[task-queue-0])
2022-10-02 14:18:28.615  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Adding newly assigned partitions: task-queue-0
2022-10-02 14:18:28.631  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=logs-module, groupId=logs-module-group] Found no committed offset for partition task-queue-0
2022-10-02 14:18:28.653  INFO  1 --- [scheduled-task-pool-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=logs-module, groupId=logs-module-group] Resetting offset for partition task-queue-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[logs-kafka:9092 (id: 1001 rack: null)], epoch=absent}}.
2022-10-02 14:18:29.845  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [pool-2-thread-1] com.worker.worker.service.Worker         : Thread number 1. In worker with task "Some task"
2022-10-02 14:18:29.847  INFO CorrelationId=4ecc0578-fba8-4855-9990-6cfc858f2d48 1 --- [pool-2-thread-1] com.worker.worker.service.Worker         : Thread number 1. Task "Some task" completed
